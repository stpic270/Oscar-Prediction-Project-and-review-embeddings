{"metadata":{"colab":{"authorship_tag":"ABX9TyP7oMzAKw5koGg8bqHEQ31J","collapsed_sections":["3KqY_FrTT2Fz","8_tyDhfmT4_j","U-anbpuqT8Sh","0SrNestTSESu","Iqab3FtfwI5G","eIVgzF8PUqPS","_3sW3MUTS0X9","oNjMu21WViSD","W7OnWa9_TAGM","OkG_Nnole_MZ","XQQcLneHfmBN","yJXn-_scoq4M"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Download packages via pip, import libraries, connect to drive","metadata":{"id":"v5KoC3NnOPZa"}},{"cell_type":"markdown","source":"## Install packages","metadata":{"id":"3KqY_FrTT2Fz"}},{"cell_type":"code","source":"! pip install -q transformers","metadata":{"id":"KpN8LQOHJQfG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! git clone https://github.com/MateVaradi/OscarPrediction.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1390,"status":"ok","timestamp":1710146329559,"user":{"displayName":"Stepha","userId":"08397602524211524021"},"user_tz":-180},"id":"Ect9IjGAMHye","outputId":"3ede0706-cbaf-4826-f3db-a26e18887c56"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import libraries","metadata":{"id":"8_tyDhfmT4_j"}},{"cell_type":"code","source":"# For data preprocessing\nimport pandas as pd\nimport numpy as np\nfrom imblearn.over_sampling import SMOTE\nfrom collections import Counter\n\n# To get text embeddings with DistilBert\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom transformers import pipeline\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n\n# For ml operations\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegressionCV, LogisticRegression\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import PredefinedSplit\nimport sklearn\n\n# For data plotting\nimport plotly.express as px\nimport plotly\nimport tqdm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os # to manipulate paths to files\nimport time # to check time\nimport pickle # to upload and download files\nimport copy # to copy variables\n\nfrom google.colab import drive # to connect to your drive\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')","metadata":{"id":"NLS39wbWJpxl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Connect to the drive","metadata":{"id":"U-anbpuqT8Sh"}},{"cell_type":"code","source":"drive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26033,"status":"ok","timestamp":1710146373433,"user":{"displayName":"Stepha","userId":"08397602524211524021"},"user_tz":-180},"id":"h2DCvUq1JtAB","outputId":"d0c4a8e8-f494-4f8b-94e8-af82d9258438"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Upload and clean data","metadata":{"id":"PrxnN11RPHTi"}},{"cell_type":"markdown","source":"## Upload the data","metadata":{"id":"fPMvWhefUBRl"}},{"cell_type":"code","source":"# Upload reviews as dicts\nwith open('/content/drive/MyDrive/project/full_rt_20_mc_reviews_dicts/full_rt_dict.pkl', 'rb') as file:\n    full_rt_dict = pickle.load(file)\n\nwith open('/content/drive/MyDrive/project/full_rt_20_mc_reviews_dicts/full_mc_dict.pkl', 'rb') as file:\n    full_mc_dict = pickle.load(file)","metadata":{"id":"t99W6s0KT5XI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Upload dataframes\ndf_with_reviews = pd.read_csv('/content/OscarPrediction/data/oscardata_bestpicture.csv')\ndf_wt_reviews = pd.read_csv('/content/OscarPrediction/data/oscardata_bestpicture.csv')","metadata":{"id":"moFBiqP7Jx4_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Clean the data","metadata":{"id":"clHZHDIWUDLY"}},{"cell_type":"code","source":"# Drop duplicates\ndf_wt_reviews = df_wt_reviews.drop_duplicates()\ndf_with_reviews = df_with_reviews.drop_duplicates()","metadata":{"id":"ru3GWx4tMcyF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get identical movie's index\nidentical = df_wt_reviews['Film'].value_counts()\nprint(identical[0:1])\ndf_wt_reviews[df_wt_reviews['Film'] == 'West Side Story']","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1709789527723,"user":{"displayName":"Stepha","userId":"08397602524211524021"},"user_tz":-180},"id":"Kn3k5K4qMm0Z","outputId":"b5547986-8276-4da6-d1af-89f68e90f6aa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Drop film by 1962 and map reviews","metadata":{"id":"cV0XTYpxNdtJ"}},{"cell_type":"code","source":"# Drop film West Side Story by 1962 for both dataframes cause it already has one movie with the same name\ndf_wt_reviews = df_wt_reviews.drop(index=5)\ndf_wt_reviews = df_wt_reviews.reset_index(drop=True)\n\ndf_with_reviews = df_with_reviews.drop(index=5)\ndf_with_reviews = df_with_reviews.reset_index(drop=True)","metadata":{"id":"Xihtm75ENjT0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add reviews to dataframe with reviews\ndf_with_reviews['rt reviews'] = df_with_reviews['Film'].map(full_rt_dict)\ndf_with_reviews['mc reviews'] = df_with_reviews['Film'].map(full_mc_dict)","metadata":{"id":"LiyWctEITtMK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initialize model, check tests and get embeddings. You can skip this part and upload embeddings directly","metadata":{"id":"0SrNestTSESu"}},{"cell_type":"code","source":"# Get reviews as lists if you are going to get embeddings\nrt_reviews = df_with_reviews['rt reviews']\nmc_reviews = df_with_reviews['mc reviews']","metadata":{"id":"2gMxCIxL8TPw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initialize model","metadata":{"id":"BhAjmzv2-JB5"}},{"cell_type":"code","source":"tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\nmodel = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\nmodel.to(device)","metadata":{"id":"ZW_Oo-cm-LM1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.classifier","metadata":{"id":"Lq2Ki_VfBwQu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run some tests\nYou can skip the following code and just get the embeddings","metadata":{"id":"cjnodbLc-QDy"}},{"cell_type":"code","source":"text = [\"Hello, my dog is cute, but it poo's and it stinks often. However, I love it\",\n        \"Hiii, My name is Stepan\"]\n\ninputs = tokenizer(text, return_tensors=\"pt\", padding='longest')\ninputs.to(device)\ndistilbert_output = model.distilbert(**inputs)\n\nprint(\"Input_ids shape = \", inputs.input_ids.shape)\n\nhidden_state = distilbert_output[0]\nprint('Hidden_state shape', hidden_state.shape)","metadata":{"id":"HKs7zZHx-MAL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get logits","metadata":{"id":"Y4c9ODms-pS1"}},{"cell_type":"code","source":"pooled_output = hidden_state[:, 0]  # (bs, dim)\n# pooled_output = torch.mean(hidden_state, dim=1)\nprint(pooled_output.shape)\npooled_output = model.pre_classifier(pooled_output)  # (bs, dim)\nprint(pooled_output.shape)\npooled_output = nn.ReLU()(pooled_output)  # (bs, dim)\nprint(pooled_output.shape)\npooled_output = model.dropout(pooled_output)  # (bs, dim)\nprint(pooled_output.shape)\nlogits = model.classifier(pooled_output)  # (bs, num_labels)","metadata":{"id":"Lmrgyd5X-r2H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check logits\nlogits","metadata":{"id":"U6NMzmsR-sbb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get mood for both sentences","metadata":{"id":"xQCUpzHi-zF2"}},{"cell_type":"code","source":"predicted_class_id = logits[0].argmax().item()\nprint(\"First sentiment - \", model.config.id2label[predicted_class_id])\n\npredicted_class_id = logits[1].argmax().item()\nprint(\"Second sentiment - \", model.config.id2label[predicted_class_id])","metadata":{"id":"y7Nn7pzd-4Nu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get embeddings. Everything as one function","metadata":{"id":"L-cf6S_5_Hx-"}},{"cell_type":"code","source":"def get_hidden_state(reviews):\n    \"\"\"\n    get hidden states\n    \"\"\"\n    with torch.no_grad():\n        # If there is nan instead of reviews thenreturn None\n        if type(reviews) == type(np.nan):\n            return None\n\n        inputs = tokenizer(reviews, return_tensors=\"pt\", padding='longest')\n        inputs.to(device)\n        distilbert_output = model.distilbert(**inputs)\n        hidden_state = distilbert_output[0]\n        hidden_state = hidden_state[:, 0]\n        # Uncomment this string to get hidden states mean\n        # hidden_state = torch.mean(hidden_state, dim=0)\n        return hidden_state\n\ndef get_prediction(hidden_state):\n    \"\"\"\n    Get prediction if prediction parameter is True in get_embeddings function\n    \"\"\"\n    with torch.no_grad():\n\n        pooled_output = model.pre_classifier(hidden_state)  # (bs, dim)\n        pooled_output = nn.ReLU()(pooled_output)  # (bs, dim)\n        pooled_output = model.dropout(pooled_output)  # (bs, dim)\n        logits = model.classifier(pooled_output)  # (bs, num_labels)\n\n        return logits\n\ndef get_embeddings(data, prediction=False):\n\n    \"\"\"\n    This fucntion takes in data parameter that is dict and contains text reviews and add to it embeddings\n    \"\"\"\n\n    # Copy data\n    copied_data = copy.deepcopy(data)\n\n    # loop over review's dict {'mc_reviews':mc_reviews, 'rt_reviews':rt_reviews} that were uploaded recently in the notebook\n    for j, (key, text_nested_list) in enumerate(copied_data.items()):\n        # initialise lists\n        hidden_states_list, prediction_list, sentiment_list = [], [], []\n        # iterate over reviews for each film\n        for i, text_list in enumerate(text_nested_list):\n\n            hidden_state = get_hidden_state(text_list)\n\n            # Get embeddings as a prediction if prediction parameter is True\n            if prediction:\n                if hidden_state != None:\n                    logits = torch.mean(get_prediction(hidden_state), dim=0)\n                    predicted_class_id = logits.argmax().item()\n                    sentiment = model.config.id2label[predicted_class_id]\n\n                    prediction_list.append(logits.detach().cpu().numpy())\n                    sentiment_list.append(0 if sentiment == 'NEGATIVE' else 1)\n\n                else: prediction_list.append(None); sentiment_list.append(None)\n\n            # Append hidden state\n            if hidden_state != None: hidden_states_list.append(torch.mean(hidden_state, dim=0).detach().cpu().numpy())\n            else: hidden_states_list.append(None)\n\n            if i%100==0:\n                print(\"Number of iteration - \", i)\n\n        # Add embeddings to data parameter\n        data[key+'_hidden_states'] = hidden_states_list\n        data[key+'_prediction_list'] = prediction_list\n        data[key+'_sentiment_list'] = sentiment_list\n\n    return data","metadata":{"id":"AA10HeeN8XUy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use functions above\ndata = {'mc_reviews':mc_reviews, 'rt_reviews':rt_reviews}\ndata = get_embeddings(data, prediction=True)","metadata":{"id":"LukvOoMTIJz3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.keys()","metadata":{"id":"L74hlmjTeX4_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shapes = [s.shape for s in rt_hidden_states_list]\n# sorted(shapes)","metadata":{"id":"JaxI-iENCblH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save embeddings","metadata":{"id":"Iqab3FtfwI5G"}},{"cell_type":"code","source":"with open('/content/drive/MyDrive/project/embeddings/full_data_dict.pkl', 'wb') as file:\n    pickle.dump(data, file)","metadata":{"id":"n0NzgK9kCwZ8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load embeddings, preprocess data, get train and test data","metadata":{"id":"sYvfxmvrwLjl"}},{"cell_type":"markdown","source":"## Load embeddings","metadata":{"id":"J9btc0neTyBp"}},{"cell_type":"code","source":"with open('/content/drive/MyDrive/project/embeddings/full_data_dict.pkl', 'rb') as file:\n    data = pickle.load(file)","metadata":{"id":"tlPdWmObwFvk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retrieve the lists with data\nrt_hidden_states_list, mc_hidden_states_list = data['rt_reviews_hidden_states'], data['mc_reviews_hidden_states']\nrt_reviews_prediction_list, mc_reviews_prediction_list = data['rt_reviews_prediction_list'], data['mc_reviews_prediction_list']\nrt_reviews_sentiment_list, mc_reviews_sentiment_list = data['rt_reviews_sentiment_list'], data['mc_reviews_sentiment_list']","metadata":{"id":"lsAJS-Yef32u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess data","metadata":{"id":"eIVgzF8PUqPS"}},{"cell_type":"code","source":"def fill_in_mean_values(data_list):\n\n    \"\"\"\n    This function take in data_list parameter, calculates the average variable for it and fill in average\n    \"\"\"\n    temporary_list = []\n\n    # Use it to avoid get None value as a type for the whole list\n    temporary_type, i = type(None), 0\n    while temporary_type == type(None):\n        temporary_type = type(data_list[i])\n        i += 1\n    str_type = str(temporary_type)\n\n    # Get not nan values\n    for i in range(len(data_list)):\n        if str(data_list[i]) != 'None':\n            temporary_list.append(data_list[i])\n\n    # form np arrays\n    temporary_list_numpy = np.array(temporary_list)\n\n    # Get means and type\n    mean_tensor = np.mean(temporary_list_numpy, axis=0)\n    if 'int' in str_type:\n        mean_tensor = np.round(mean_tensor).astype(int)\n\n    # Fill in means\n    data_list = [arr if type(None) != type(arr) else mean_tensor for arr in data_list]\n\n    return data_list","metadata":{"id":"xF4xQuWTwVaF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill average to the film that do not have mc reviews. YOU COULD USE IT AND FOR RT EMBEDDINGS IF THERE ARE SUCH FILMS\nmc_hidden_states_list = fill_in_mean_values(mc_hidden_states_list)\nmc_reviews_prediction_list = fill_in_mean_values(mc_reviews_prediction_list)\nmc_reviews_sentiment_list = fill_in_mean_values(mc_reviews_sentiment_list)","metadata":{"id":"04Gg_KbE1c0N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Form rt and mc dataframes\nd = mc_hidden_states_list[0].shape[0]\nrt_df = pd.DataFrame(rt_hidden_states_list, columns=[f'rt_embed_index_{i}' for i in range(d)])\nmc_df = pd.DataFrame(mc_hidden_states_list, columns=[f'mc_embed_index_{i}' for i in range(d)])\n\nrt_prediction_df = pd.DataFrame(rt_reviews_prediction_list, columns=['rt_first_dim', 'rt_second_dim'])\nmc_prediction_df = pd.DataFrame(mc_reviews_prediction_list, columns=['mc_first_dim', 'mc_second_dim'])\n\nrt_sentiment_df = pd.DataFrame(rt_reviews_sentiment_list, columns=['rt_sentiment'])\nmc_sentiment_df = pd.DataFrame(mc_reviews_sentiment_list, columns=['mc_sentiment'])","metadata":{"id":"qjREtZmkw4gk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get rid of some columns\ny = df_wt_reviews['Winner']\ndf_wt_reviews = df_wt_reviews.drop(['Category', 'Film', 'Nominee', 'Year', 'Release_date', 'MPAA_rating', 'Winner'], axis=1)","metadata":{"id":"VCASKbnKze7b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make one dataframe with embeddings\ndf_with_embeddings = pd.concat([df_wt_reviews, rt_df, mc_df], axis=1)\ndf_em_only = pd.concat([rt_df, mc_df], axis=1)\n\ndf_with_prediction_sentiment = pd.concat([df_wt_reviews, rt_prediction_df,\n                                          mc_prediction_df, rt_sentiment_df,\n                                          mc_sentiment_df], axis=1)\n\ndf_with_rt_embeddings = pd.concat([df_wt_reviews, rt_df], axis=1)\ndf_with_mc_embeddings = pd.concat([df_wt_reviews, mc_df], axis=1)\n\ndf_all = pd.concat([df_with_embeddings, df_with_prediction_sentiment], axis=1)","metadata":{"id":"r_KVyUKyx4CD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For dict dataframes with old dataframes\ndataframes = {'df_with_embeddings':df_with_embeddings,\n              'df_wt_embeddings': df_wt_reviews,\n              'df_em_only':df_em_only,\n              'df_with_prediction_sentiment':df_with_prediction_sentiment,\n              'df_with_rt_embeddings': df_with_rt_embeddings,\n              'df_with_mc_embeddings':df_with_mc_embeddings,\n              'df_all':df_all}","metadata":{"id":"xUwCpbgvUrTQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get train, test data","metadata":{"id":"_3sW3MUTS0X9"}},{"cell_type":"code","source":"# Initialize the StandardScaler\ndef scale_data(df):\n\n    scaler = StandardScaler()\n    scaled_data = scaler.fit_transform(df)\n\n    return scaled_data\n\n# Fit and transform the numerical data using StandardScaler and associate it with dataframes varable\nfor k, df in dataframes.items():\n    scaled_df = scale_data(df)\n    dataframes[k] = scaled_df","metadata":{"id":"K0aAgLcs8yi2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define parameters for train_test_split and split the data\ntest_size = 0.2\nrandom_state=43\ndata_dict = copy.deepcopy(dataframes)\n\ndef data_split(X,y, test_size=0.5, random_state=43):\n    return train_test_split(X,y, test_size=test_size, random_state=random_state)\n\nfor k, df in data_dict.items():\n    t = (X_train, X_test, y_train, y_test) = data_split(X=df,y=y,test_size=test_size,\n                                                        random_state=random_state)\n    data_dict[k] = t","metadata":{"id":"0G8p-AUB2A0_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Make sure that the data is splitted correctly, i.e. splits are made in such way that we can see the difference between data with text embeddings as 768 tensor dim and 2 tensor dim with sentiment mark and without embeddings","metadata":{"id":"oNjMu21WViSD"}},{"cell_type":"code","source":"print(data_dict['df_all'][0])\nprint('-'*100)\nprint(data_dict['df_with_embeddings'][0])\nprint('-'*100)\nprint(data_dict['df_with_prediction_sentiment'][0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":241,"status":"ok","timestamp":1709793315650,"user":{"displayName":"Stepha","userId":"08397602524211524021"},"user_tz":-180},"id":"0JeWlAksZ00b","outputId":"5a465a46-8f20-4db8-f94a-ffea8406e87f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initialize, train models and plot results","metadata":{"id":"F2eNznHrS8zA"}},{"cell_type":"markdown","source":"## Some utils that will be used in this chapter and in \"Use SMOTE to add data\" one. You can just activate the cell and skip them or have have a look on it","metadata":{"id":"6eFJH6iCTMIW"}},{"cell_type":"code","source":"def plot_2_cm(cm1, cm2, name_1, name_2, class_names):\n\n    \"\"\"\n    This function takes parameters for plotting 2 confusion matrices and compare them\n\n    Parameters:\n    cm1: The first confusion matrix\n    cm2: The second confusion matrix\n    name_1 (str): Name for the cm1 on the plot\n    name_2 (str): Name for the cm2 on the plot\n    class_names (list): Names for the classes\n    \"\"\"\n\n    # Create subplots for confusion matrices side by side\n    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n\n    # Plot confusion matrix 1\n    sns.heatmap(cm1, annot=True, cmap='Blues', fmt='d', cbar=False, ax=axs[0])\n    axs[0].set_title(name_1)\n    axs[0].set_xlabel('Predicted Label')\n    axs[0].set_ylabel('True Label')\n    axs[0].set_xticklabels(class_names)\n    axs[0].set_yticklabels(class_names)\n\n    # Plot confusion matrix 2\n    sns.heatmap(cm2, annot=True, cmap='Oranges', fmt='d', cbar=False, ax=axs[1])\n    axs[1].set_title(name_2)\n    axs[1].set_xlabel('Predicted Label')\n    axs[1].set_ylabel('True Label')\n    axs[1].set_xticklabels(class_names)\n    axs[1].set_yticklabels(class_names)\n\n    plt.tight_layout()\n    plt.show()\n\ndef plot_2_reports(report_1, report_2, name_1, name_2):\n\n    \"\"\"\n    This function operates in a similar way to plot_2_cm function - plot and\n    compare 2 reports from sklearn's classification_report\n\n    Parameters:\n    report_1: The first classification report\n    report_2: The second classification report\n    name_1 (str): Name for the report_1 on the plot\n    name_2 (str): Name for the report_2 on the plot\n    \"\"\"\n\n    # Convert classification reports to pandas DataFrames for easier manipulation\n    df_1 = pd.DataFrame(report_1).T\n    df_2 = pd.DataFrame(report_2).T\n\n    # Reset index for DataFrames\n    df_1.reset_index(inplace=True)\n    df_2.reset_index(inplace=True)\n\n    # Set index name for the DataFrames\n    df_1.rename(columns={'index': 'Metric'}, inplace=True)\n    df_2.rename(columns={'index': 'Metric'}, inplace=True)\n\n    # Create a figure and axis\n    fig, ax = plt.subplots(2, 1, figsize=(20, 5))\n\n    # Plot the classification reports as tables\n    ax[0].axis('off')\n    ax[0].table(cellText=df_1.values, colLabels=df_1.columns, cellLoc='center', loc='center')\n    ax[0].set_title(name_1)\n\n    ax[1].axis('off')\n    ax[1].table(cellText=df_2.values, colLabels=df_2.columns, cellLoc='center', loc='center')\n    ax[1].set_title(name_2)\n\n    plt.show()\n\ndef plot_model_results(model_1, model_2, model_name,\n                       X_test_1, y_test_1,\n                       X_test_2, y_test_2, class_names):\n\n    \"\"\"\n    This function compares 2 models: gets test predictions and uses previous\n    functions plot_2_reports and plot_2_cm to plot differents between 2 algorithms\n\n    Parameters:\n    model_1: The first sklearn model\n    model_2: The second sklearn model\n    X_test_1: Test data for the first model\n    y_test_1: Labels for the first test data\n    X_test_2: Test data for the second model\n    y_test_2: Labels for the second test data\n    class_names (list): Names for the classes\n    \"\"\"\n\n    # Get prediction and classification report for the first model\n    y_pred_1 = model_1.predict(X_test_1)\n    report_1 = classification_report(y_test_1, y_pred_1,\n                                     target_names=class_names, output_dict=True)\n\n    # Get prediction and calssification report for the second model\n    y_pred_2 = model_2.predict(X_test_2)\n    report_2 = classification_report(y_test_2,y_pred_2,\n                                     target_names=class_names, output_dict=True)\n\n    # Plot 2 reports\n    plot_2_reports(report_1=report_1, report_2=report_2,\n                  name_1=f'{model_name} with reviews', name_2=f'{model_name} without reviews')\n\n    # Get confusion matrices\n    cm1 = confusion_matrix(y_test_1,y_pred_1)\n    cm2 = confusion_matrix(y_test_2,y_pred_2)\n\n    # Plot confusion matrices\n    plot_2_cm(cm1, cm2, name_1=f'{model_name} with reviews confusion matrix',\n              name_2=f'{model_name} without reviews confusion matrix',\n              class_names=class_names)\n\ndef plot_and_compare(pairs_list, model_name, models_dict, data_dict):\n\n    \"\"\"\n    This function compares 2 models trained on different datasets (usually with\n    embeddings and without it) and plot results with classification reports and\n    confusion matrices using plot_model_results function\n\n    Parameters:\n    pairs_list (list): List that contains tuples with names pair of comparable\n    data. Values are the keys to data_dict\n\n    data_dict (dict): Dict with the data\n    model_name: Name of the model that was trained on 2 different datasets\n    models_dict (dict): Dict with trained models\n    \"\"\"\n\n    current_model = models_dict[model_name]\n\n    for pair in pairs_list:\n\n        key_1, key_2 = pair\n        model_1, model_2 = current_model[key_1], current_model[key_2]\n        _, X_test_1, _, y_test_1 = data_dict[key_1]\n        _, X_test_2, _, y_test_2 = data_dict[key_2]\n\n        plot_model_results(model_1, model_2, model_name.upper(),\n                           X_test_1, y_test_1,\n                           X_test_2, y_test_2, class_names)\n\ndef compute_tsne(scaled_data_1, scaled_data_2,\n                 n_comp_1=2, n_comp_2=2):\n\n    \"\"\"\n    This function computes TSNE for data\n\n    Parameters:\n    scaled_data_1: Data for the first graphic\n    scaled_data_2: Data for the second graphic\n    n_comp_1 (int): Dimension to which shrink the first data\n    n_comp_2 (int): Dimension to which shrink the second data\n\n    Returns:\n    tuple: pair of trained TSNE\n    \"\"\"\n\n    # Use TSNE to reduce dimensionality for the first data\n    tsne_model_1 = TSNE(n_components=n_comp_1, random_state=42)\n    tsne_values_1 = tsne_model_1.fit_transform(scaled_data_1)\n\n    # Use TSNE to reduce dimensionality for the second data\n    tsne_model_2 = TSNE(n_components=n_comp_2, random_state=42)\n    tsne_values_2 = tsne_model_2.fit_transform(scaled_data_2)\n\n    return tsne_values_1, tsne_values_2\n\ndef plot_2_TSNE(tsne_1 , tsne_2,\n                y_1, y_2,\n                title_1 = 't-SNE WITH embeddings',\n                title_2 = 't-SNE WITHOUT embeddings'\n                ):\n\n    \"\"\"\n    This function takes TSNE values from compute_tsne function and plots the results\n\n    Parameters:\n    scaled_data_1: Data for the first graphic\n    scaled_data_2: Data for the second graphic\n    n_comp_1 (int): Dimension to which shrink the first data\n    n_comp_2 (int): Dimension to which shrink the second data\n    title_1 (str): Title for the first model\n    title_2 (str): Title for the second model\n    \"\"\"\n\n    # Set the first graphic\n    fig1 = px.scatter(\n    x = tsne_1[:,0],\n    y = tsne_1[:,1],\n    color = y_1,\n    title = title_1, width = 800, height = 600,\n    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r\n    )\n\n    # Set the second graphic\n    fig2 = px.scatter(\n    x = tsne_2[:,0],\n    y = tsne_2[:,1],\n    color = y_2,\n    title = title_2, width = 800, height = 600,\n    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r\n    )\n\n    # Change the titles for both graphics\n    fig1.update_layout(\n        xaxis_title = 'first component',\n        yaxis_title = 'second component')\n\n    fig2.update_layout(\n        xaxis_title = 'first component',\n        yaxis_title = 'second component')\n\n    # Plot graphics\n    fig1.show()\n    fig2.show()\n\ndef k_means_neigbours_graph(scaled_data_1, scaled_data_2, title_1, title_2):\n\n    \"\"\"\n    This function calculates k-means with different amount of k, computes\n    silhouette score and plots the result\n\n    Parameters:\n    scaled_data_1: Data for the first k-means\n    scaled_data_2: Data for the second k-means\n    \"\"\"\n\n    # Initialise lists\n    silhouette_scores_1, silhouette_scores_2 = [], []\n\n    # Loop to compute k-means and silhouette score for the first data\n    for k in tqdm.tqdm(range(2, 51)):\n        kmeans = KMeans(n_clusters=k,\n                        random_state=42,\n                        n_init = 'auto').fit(scaled_data_1)\n        kmeans_labels = kmeans.labels_\n        silhouette_scores_1.append(\n            {\n                'k': k,\n                'silhouette_score': silhouette_score(scaled_data_1,\n                    kmeans_labels, metric = 'cosine')\n            }\n        )\n\n    # Loop to compute k-means and silhouette score for the second data\n    for k in tqdm.tqdm(range(2, 51)):\n        kmeans = KMeans(n_clusters=k,\n                        random_state=42,\n                        n_init = 'auto').fit(scaled_data_2)\n        kmeans_labels = kmeans.labels_\n        silhouette_scores_2.append(\n            {\n                'k': k,\n                'silhouette_score': silhouette_score(scaled_data_2,\n                    kmeans_labels, metric = 'cosine')\n            }\n        )\n\n    # Set graphics\n    fig1 = px.line(pd.DataFrame(silhouette_scores_1).set_index('k'),\n          title = f'<b>The best number of classes for {title_1}</b>',\n          labels = {'value': 'silhoutte score'},\n          color_discrete_sequence = plotly.colors.qualitative.Alphabet)\n    fig1.update_layout(showlegend = False)\n\n    fig2 = px.line(pd.DataFrame(silhouette_scores_2).set_index('k'),\n          title = f'<b>The best number of classes for {title_2}</b>',\n          labels = {'value': 'silhoutte score'},\n          color_discrete_sequence = plotly.colors.qualitative.Alphabet)\n    fig2.update_layout(showlegend = False)\n\n    # Plot the result\n    fig1.show()\n    fig2.show()\n\ndef train_svm(X_train, y_train, **params):\n\n    \"\"\"\n    This function takes in data and train SVM model\n\n    Parameters:\n    X_train: Data to train SVM\n    y_train: Labels for the train data\n\n    Returns:\n    trained SVM model\n    \"\"\"\n\n    svm = SVC(**params)\n    svm.fit(X_train, y_train)\n\n    return svm\n\ndef train_random_forest(X_train, y_train, **params):\n\n    \"\"\"\n    This function takes in data and train random forest model\n\n    Parameters:\n    X_train: Data to train random forest\n    y_train: Labels for the train data\n\n    Returns:\n    trained random forest model\n    \"\"\"\n\n    rf = RandomForestClassifier(**params)\n    rf.fit(X_train, y_train)\n\n    return rf\n\ndef train_logistic_regression(X_train, y_train, **params):\n\n    \"\"\"\n    This function takes in data and train random logistic regression\n\n    Parameters:\n    X_train: Data to train logistic regression\n    y_train: Labels for the train data\n\n    Returns:\n    trained logistic regression model\n    \"\"\"\n\n    lr = LogisticRegression(**params)\n    lr.fit(X_train, y_train)\n\n    return lr\n\ndef get_trained_model(X_train, y_train, model_name=\"svm\", **params):\n\n    \"\"\"\n    This function takes in data and chooses which model to train according to\n    model_name. It also takes in model params\n\n    Parameters:\n    X_train: Data to train model\n    y_train: Labels for the train data\n    model_name (str): name for the train model\n    **params: dict with train parameters\n\n    Returns:\n    trained trained model according to the name\n    \"\"\"\n\n    if model_name == 'svm':\n        return train_svm(X_train, y_train, **params)\n\n    elif model_name == 'random_forest':\n        return train_random_forest(X_train, y_train, **params)\n\n    else:\n        return train_logistic_regression(X_train, y_train, **params)","metadata":{"id":"pqqaZUGt4zER"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initialize and train models","metadata":{"id":"W7OnWa9_TAGM"}},{"cell_type":"code","source":"# Class names for labels\nclass_names = ['non oscar winners', 'oscar winners']","metadata":{"id":"1PbCbGZA3Ojs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Models name\nmodels = ['svm', 'random_forest', 'logistic_regression']\n# Initialise model names\nmodels_dict = {}\n# Initialise model' parameters using nested dict\nparams_dict = {'svm':{'random_state':101},\n               'random_forest':{'random_state':101, 'n_estimators':250},\n               'logistic_regression':{'random_state':101,'max_iter':5000, 'solver':\"newton-cg\"}}\n\n# Train models with data_dict that has been created before\nfor model in models:\n    current_dict = models_dict[model] = {}\n    params = params_dict[model]\n    for k, data_tuple in data_dict.items():\n        X_train, _, y_train, _ = data_tuple\n        current_dict[k] = get_trained_model(X_train, y_train, model_name=model, **params)","metadata":{"id":"X1KhRrVGQPcG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check models\nmodels_dict","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1709793334077,"user":{"displayName":"Stepha","userId":"08397602524211524021"},"user_tz":-180},"id":"mgvf_aJKUy_Y","outputId":"48bc75b4-774a-454e-b2a7-a62f27ff438b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot results","metadata":{"id":"OkG_Nnole_MZ"}},{"cell_type":"code","source":"# Define comparable pairs\npairs_list = [('df_with_embeddings', 'df_wt_embeddings'),\n              ('df_with_prediction_sentiment', 'df_all')]\n\n# Plot results for svm model\nmodel_name = 'svm'\nplot_and_compare(pairs_list, model_name, models_dict,data_dict)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2100,"status":"ok","timestamp":1709793336174,"user":{"displayName":"Stepha","userId":"08397602524211524021"},"user_tz":-180},"id":"gWAMZi6aeKCK","outputId":"d9234ecf-faf1-4ca4-9d8d-a449f2dfccc0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define comparable pairs\npairs_list = [('df_with_embeddings', 'df_wt_embeddings'),\n                  ('df_with_prediction_sentiment', 'df_all')]\n\n# Plot results for random forest model\nmodel_name = 'random_forest'\nplot_and_compare(pairs_list, model_name, models_dict, data_dict)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3336,"status":"ok","timestamp":1709793339508,"user":{"displayName":"Stepha","userId":"08397602524211524021"},"user_tz":-180},"id":"HUY1F8HaVJ8-","outputId":"65c1d90a-2074-4058-add9-afbf95780afd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define comparable pairs\npairs_list = [('df_with_embeddings', 'df_wt_embeddings'),\n                  ('df_with_prediction_sentiment', 'df_all')]\n\n# Plot results for logistic regression model\nmodel_name = 'logistic_regression'\nplot_and_compare(pairs_list, model_name, models_dict, data_dict)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2747,"status":"ok","timestamp":1709793342253,"user":{"displayName":"Stepha","userId":"08397602524211524021"},"user_tz":-180},"id":"HjEmkxjVVn36","outputId":"6ec5ff0a-eb43-4a1a-b190-7ebdb0c6fc73"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### As we can see all models except logistic regression are struggling with prediction data with reviews 768 text embedding dimension from DistilBert. But the results are better when only logits and sentiment mark are used. It is also obiously that there is imbalance in data distribution\n\n### Cause of these reasons data will be adjuncted with SMOTE and later predictions will be made on the following datasets: df_wt_embeddings and df_with_prediction_sentiment\n\n### But the SMOTE will be used for all data, so you can play around and check results","metadata":{"id":"a4lhPYQ2drIJ"}},{"cell_type":"markdown","source":"# Before SMOTE, let's take a look on data distribution using TSNE","metadata":{"id":"XQQcLneHfmBN"}},{"cell_type":"code","source":"data_pairs_list = [('df_with_prediction_sentiment', 'df_wt_embeddings')]\ntitle_pairs_list = [('Data with embeddings', 'Data without embeddings')]\n\nfor key_pair, title_pair in zip(data_pairs_list, title_pairs_list):\n\n    key_1, key_2 = key_pair\n    title_1, title_2 = title_pair\n\n    data_1 = dataframes[key_1]\n    data_2 = dataframes[key_2]\n\n    tsne_1, tsne_2 = compute_tsne(scaled_data_1=data_1,\n                                  scaled_data_2=data_2,\n                                  n_comp_1=2, n_comp_2=2)\n\n    print(tsne_1.shape, tsne_2.shape)\n    plot_2_TSNE(tsne_1, tsne_2, y, y,\n                title_1=title_1, title_2=title_2)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6188,"status":"ok","timestamp":1709793348438,"user":{"displayName":"Stepha","userId":"08397602524211524021"},"user_tz":-180},"id":"-8WyVvpuS51z","outputId":"e3d998ac-ce54-4c86-b104-1329d08d56d2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Use SMOTE to add data, and have a look on the graphics","metadata":{"id":"yJXn-_scoq4M"}},{"cell_type":"code","source":"def add_data_smote(X, y):\n\n    \"\"\"\n    This function adds data to imbalanced class\n\n    Parameters:\n    X: Data to which will be sampled new data\n    y: Labels for data, new labels also will be sampled\n\n    Returns:\n    Dataset (tuple) with new data for imbalanced class\n    \"\"\"\n\n    smote = SMOTE(sampling_strategy='auto', random_state=random_state)\n    X_art, y_art = smote.fit_resample(X,y)\n\n    return X_art, y_art","metadata":{"id":"qxGQtCjARPc2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sample data to imbalanced class","metadata":{"id":"0uzRaSuyZO7p"}},{"cell_type":"code","source":"art_data_dict = copy.deepcopy(data_dict)\n\n# Use SMOTE for all data and add them to new dict\nfor k, v in art_data_dict.items():\n\n    X_train, X_test, y_train, y_test = v\n    art_X_train, art_y_train = add_data_smote(X_train, y_train)\n\n    art_data_dict[k] = (art_X_train, X_test, art_y_train, y_test)\n\n# Check the number of imbalanced class before and after SMOTE\nk = 'df_with_embeddings'\nX_train, X_test, y_train, y_test = data_dict[k]\nart_X_train, X_test, art_y_train, y_test = art_data_dict[k]\n\ncounter, art_counter = Counter(y_train), Counter(art_y_train)\nprint(\"Before SMOTE embeddings data\", counter)\nprint(\"After SMOTE embeddings data\", art_counter)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":221,"status":"ok","timestamp":1709793375522,"user":{"displayName":"Stepha","userId":"08397602524211524021"},"user_tz":-180},"id":"iMADIJSTSACm","outputId":"b47d585d-7eb7-4949-98eb-5b8851ba3203"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's have a look on X_train with SMOTE and compare it to data without SMOTE","metadata":{"id":"JbfG1QyJxwbc"}},{"cell_type":"code","source":"data_pairs_list = [('df_with_prediction_sentiment', 'df_wt_embeddings')]\ntitle_pairs_list = [('Data with embeddings and with SMOTE', 'Data with embeddings and without SMOTE'),\n                    ('Data without embeddings and with SMOTE', 'Data without embeddings and without SMOTE')]\ndata_list = [(art_data_dict, data_dict)]\n\nfor key_pair in data_pairs_list:\n    for dict_pair in data_list:\n        d_1, d_2 = dict_pair\n        for key, title_pair in zip(key_pair, title_pairs_list):\n            title_1, title_2 = title_pair\n\n            data_1 = d_1[key]\n            X_train_1, _,y_train_1,_ = data_1\n\n            data_2 = d_2[key]\n            X_train_2, _,y_train_2,_ = data_2\n\n            tsne_1, tsne_2 = compute_tsne(scaled_data_1=X_train_1,\n                                          scaled_data_2=X_train_2,\n                                          n_comp_1=2, n_comp_2=2)\n\n            plot_2_TSNE(tsne_1, tsne_2, y_train_1, y_train_2,\n                        title_1=title_1, title_2=title_2)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":12987,"status":"ok","timestamp":1709793398385,"user":{"displayName":"Stepha","userId":"08397602524211524021"},"user_tz":-180},"id":"KOrWRrrakYax","outputId":"5b1b4ead-1679-4b67-8b09-0e8afc2b9c86"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusions about SMOTE:\n**SMOTE (Synthetic Minority Over-sampling Technique)** is a technique used to address class imbalance in datasets by generating synthetic samples of the minority class.\n\nWhen comparing datasets with and without SMOTE using t-SNE (t-distributed Stochastic Neighbor Embedding), a popular technique for visualizing high-dimensional data in lower dimensions, the main differences you may observe are:\n\n1) **Improved Separation**: With SMOTE, you might see better separation between the classes in the t-SNE plot. This is because SMOTE helps in creating synthetic samples that fill the gaps between clusters, making the classes more distinguishable.\n\n2) **Increased Clustering**: SMOTE can lead to denser clusters of points representing the minority class in the t-SNE plot, as the synthetic samples help in expanding the representation of the minority class in the feature space.\n\n3) **Balanced Distribution**: Without SMOTE, it is obviously observed that there is imbalanced distribution of points in the t-SNE plot, with the majority class dominating the visual representation. In contrast, using SMOTE can lead to a more balanced distribution of points, reflecting the improved class balance in the dataset.\n\nAll three main points are presented on the plot\n\n**In summary**, using SMOTE to balance class distribution and add synthetic samples to the minority class can result in improved model performance, better generalization, and more distinct separation between classes in visualizations like t-SNE plots.","metadata":{"id":"eKYMEzDwgCbf"}},{"cell_type":"markdown","source":"# Let's explore how k-means algorithm makes separation on clusters and also let's check the best number of class according to silhouette score","metadata":{"id":"yKkiFGVYlPxO"}},{"cell_type":"code","source":"data_pairs_list = [('df_with_prediction_sentiment', 'df_wt_embeddings')]\ntitle_pairs_list = [('Data with embeddings and with SMOTE', 'Data with embeddings and without SMOTE'),\n                    ('Data without embeddings and with SMOTE', 'Data without embeddings and without SMOTE')]\n\ndata_list = [(art_data_dict, data_dict)]\n\nfor key_pair in data_pairs_list:\n    for dict_pair in data_list:\n        d_1, d_2 = dict_pair\n        for key, title_pair in zip(key_pair, title_pairs_list):\n            title_1, title_2 = title_pair\n\n            data_1 = d_1[key]\n            X_train_1, _,y_train_1,_ = data_1\n\n            data_2 = d_2[key]\n            X_train_2, _,y_train_2,_ = data_2\n\n            k_means_neigbours_graph(scaled_data_1=X_train_1, scaled_data_2=X_train_2,\n                                    title_1=title_1, title_2=title_2)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":10090,"status":"ok","timestamp":1709795677269,"user":{"displayName":"Stepha","userId":"08397602524211524021"},"user_tz":-180},"id":"j0et8UJUBtv7","outputId":"921f278a-6c80-4dd4-cea6-e094678ba25a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusions about k-means and silhouette score for datasets\n\n**Silhouette scores** are used to measure the quality of clustering in unsupervised machine learning algorithms like K-means. A higher silhouette score indicates that the clusters are well apart from each other and clearly distinguished. When comparing datasets with and without SMOTE using silhouette scores for the K-means algorithm, the main differences that may be observed are:\n\n1) **Impact on Cluster Separation**: When using SMOTE to balance class distribution, the addition of synthetic samples can lead to clearer separation between clusters in the feature space. It could be seen that higher silhouette scores in datasets with SMOTE as the clusters are better defined and less overlapping compared to datasets without SMOTE.\n\n2) **Effect on Cluster Purity**: SMOTE may help improve the purity of clusters by ensuring that the minority class is adequately represented in the dataset. This can lead to more cohesive and distinct clusters, reflected in higher silhouette scores for datasets with SMOTE compared to those without it.\n\n3) **Handling Class Imbalance**: In datasets without SMOTE, class imbalance can often result in skewed clustering, with the majority class dominating the clusters. By using SMOTE to address class imbalance, the K-means algorithm can perform better in distinguishing between different classes, leading to improved silhouette scores.\n\nAccording to the notes above it is really that Silhouette score for data with SMOTE with 2 classes are higher than without it. However, SMOTE also creates more clusters for our data in such way that Silhouette score is higher for the number of classes than 2 which could complikate prediction for models on test set","metadata":{"id":"InBOL6pBvBNe"}},{"cell_type":"markdown","source":"# Train models and check the results","metadata":{"id":"hlpQMMV_f8vd"}},{"cell_type":"markdown","source":"## Train models on data with SMOTE. You can try default parameters but in the following parameters will be obtained via grid search. By the way, models trained on data with SMOTE and embeddings give better prediction, and such results can be explored after using grid search","metadata":{"id":"04e85_DYZ6Oy"}},{"cell_type":"code","source":"models = ['svm', 'random_forest', 'logistic_regression']\nart_models_dict = {}\nparams_dict = {'svm':{'random_state':101},\n               'random_forest':{'random_state':101, 'n_estimators':250},\n               'logistic_regression':{'random_state':101,'max_iter':5000, 'solver':\"newton-cg\"}}\n\nfor model in models:\n    current_dict = art_models_dict[model] = {}\n    params = params_dict[model]\n    for k, data_tuple in art_data_dict.items():\n        X_train, _, y_train, _ = data_tuple\n        current_dict[k] = get_trained_model(X_train, y_train, model_name=model, **params)","metadata":{"id":"-gJli9lFUz7X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define function to get optimal parameters for the models","metadata":{"id":"nvzkSOKEaAcq"}},{"cell_type":"code","source":"def use_searchgrid(models, data_dict, params_grid, keys, scoring='f1', verbose=3):\n\n    \"\"\"\n    This function selects parameters for the models using grid search\n    on passed data with specified params\n\n    Parameters:\n    models (list): List with model names (also these are the keys for params_grid)\n    params_grid (dict): Nested grid with train parameters for each model in\n    models list\n\n    data_dict (dict): Dict with data on which models will be trained\n    keys (list): List with pair keys for the data_dict\n    scoring (str): Specify which metric to use when test parameters for model on\n    test data (from data_dict)\n    verbose (int) : This variable specify how much information to print\n\n    Returns:\n    grid_dict (dict) that contains models and best parameters which are found\n    on test data\n    \"\"\"\n\n    # define the data\n    grid_dict = {}\n\n    # Choose which model to train\n    for model in models:\n        current_dict = grid_dict[model] = {}\n\n        if model == 'svm':\n            estimator = SVC()\n        elif model == 'random_forest':\n            estimator = RandomForestClassifier()\n        else:\n            estimator = LogisticRegression()\n\n        # Get params according to the model name\n        param_grid = params_grid[model]\n\n        for key_pair in keys:\n            for k in key_pair:\n                # Retrieve the data from the dict\n                X_train, X_test, y_train, y_test = data_dict[k]\n                # Concatenate train and test data into one array\n                x, y = np.concatenate((X_train, X_test), axis=0), np.concatenate((y_train, y_test), axis=0)\n                # Specify the data indeces (1 for train and 0 for test)\n                test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n                ps = PredefinedSplit(test_fold)\n                # Initialise grid search\n                grid = GridSearchCV(estimator, param_grid, refit = False, verbose = verbose, cv=ps, scoring=scoring)\n                # fitting the model for grid search\n                grid.fit(x, y)\n\n                current_dict[k] = grid\n\n    return grid_dict","metadata":{"id":"KwA2_qnsqYft"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_temporary_dict(grid_dict, keys, data_dict, model_name):\n\n    \"\"\"\n    This function creates temporary dict and fill in models trained one the\n    best params from grid search to plot results\n\n    Parameters:\n    grid_dicr (dict): Models from grid dict and best parameters for them\n    keys (list): List with data pair of key to data_dict\n    data_dict (dict): Dict that contains data on which model will be trained on\n    with the best parameters\n\n    model_name (str): Name for the model\n\n    Returns:\n    temporary_dict (dict): Dict with models trained on keys data with the best\n    parameters\n    \"\"\"\n    temporary_dict = {model_name:{}}\n    for key_pair in keys: # iterate over data pairs\n        for key in key_pair: # iterate over data in a pair\n            # Get best parameters of the model\n            dict_with_params = grid_dict[model_name][key].best_params_\n            # Retrieve data\n            X_train, _, y_train, _ = data_dict[key]\n            # Train model\n            trained_model = get_trained_model(X_train, y_train, model_name=model_name, **dict_with_params)\n            # Append model and data\n            temporary_dict[model_name][key] = trained_model\n\n    return temporary_dict","metadata":{"id":"V2Z_6TDfsk_q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keys = [('df_with_prediction_sentiment', 'df_wt_embeddings')]\nmodels_name = ['svm']\n# defining parameter range\nparams_grid = {\n              'svm':\n               {'C': [0.1, 0.5, 1, 10, 100, 1000],\n              'gamma': [0.03, 0.02, 0.01, 0.0001,0.0002, 0.0003],\n              'kernel': ['rbf', 'poly'],\n              'random_state':[101,102]},\n               }\n\ngrid_dict = use_searchgrid(models_name, art_data_dict, params_grid, keys, scoring='f1', verbose=3)\n\n\nfor model_name in models_name: # iterate over model name\n    temporary_model_dict = get_temporary_dict(grid_dict, keys,\n                                              data_dict=art_data_dict,\n                                              model_name=model_name)\n\n    # Plot the test results\n    plot_and_compare(keys, model_name,\n                    models_dict=temporary_model_dict,\n                    data_dict=art_data_dict)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6130,"status":"ok","timestamp":1709794017263,"user":{"displayName":"Stepha","userId":"08397602524211524021"},"user_tz":-180},"id":"Cc5gH6Squle7","outputId":"47e24be8-f05a-4e71-d0c3-38920bf21ef4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keys = [('df_with_prediction_sentiment', 'df_wt_embeddings')]\nmodels_name = ['random_forest']\n# defining parameter range\nparams_grid = {\n              'random_forest':\n               {'max_depth':[8,9,10],\n              'n_estimators':[16,17,18],\n              'max_features':['sqrt', 11, 12,13, None],\n              'min_samples_leaf':[6,7,8],\n              'min_samples_split':[6,7,8],\n              'random_state':[101, 102]},\n               }\n\ngrid_dict = use_searchgrid(models_name, art_data_dict, params_grid, keys, scoring='f1', verbose=3)\n\n\nfor model_name in models_name: # iterate over model name\n    temporary_model_dict = get_temporary_dict(grid_dict, keys,\n                                              data_dict=art_data_dict,\n                                              model_name=model_name)\n\n    # Plot the test results\n    plot_and_compare(keys, model_name,\n                    models_dict=temporary_model_dict,\n                    data_dict=art_data_dict)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":76332,"status":"ok","timestamp":1709794500013,"user":{"displayName":"Stepha","userId":"08397602524211524021"},"user_tz":-180},"id":"_XyUz0-cxq2q","outputId":"cad2b058-3fb1-4018-f02e-cb79eb0695a7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keys = [('df_with_prediction_sentiment', 'df_wt_embeddings')]\nmodels_name = ['logistic_regression']\n# defining parameter range\nparams_grid = {\n              'logistic_regression':\n               {'solver':['newton-cg', 'liblinear'],\n                'max_iter':[100, 150],\n                'penalty': ['l2', 'l1'],\n                'random_state': [101, 102],\n                'C': [0.008, 0.01, 0.03, 0.05],\n                'fit_intercept':[True, False],\n                'intercept_scaling':[0.35, 0.4, 0.45],\n               }\n               }\n\ngrid_dict = use_searchgrid(models_name, art_data_dict, params_grid, keys, scoring='f1', verbose=3)\n\nfor model_name in models_name: # iterate over model name\n    temporary_model_dict = get_temporary_dict(grid_dict, keys,\n                                              data_dict=art_data_dict,\n                                              model_name=model_name)\n\n    # Plot the test results\n    plot_and_compare(keys, model_name,\n                    models_dict=temporary_model_dict,\n                    data_dict=art_data_dict)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":7764,"status":"ok","timestamp":1709794097926,"user":{"displayName":"Stepha","userId":"08397602524211524021"},"user_tz":-180},"id":"vn8QFATT3Mnf","outputId":"0400c74a-ca34-44c0-f3fb-a3c47cf8628c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusions about trained models on data with SMOTE\n\n**SMOTE (Synthetic Minority Over-sampling Technique)** is a technique used to address class imbalance in datasets by generating synthetic samples of the minority class. When using the SMOTE library to add data to a dataset, the following improvements can be expected for models:\n\n1) **Improved Model Performance**: By adding synthetic samples to the minority class, SMOTE helps balance the class distribution in the dataset. This leads to better training of machine learning models, reduced bias towards the majority class, and improved prediction performance, especially for classifiers that are sensitive to class imbalance.\n\n2) **Reduced Overfitting**: The synthetic samples generated by SMOTE help in providing more representative training data for the minority class, which can reduce overfitting that may occur when training on imbalanced datasets.\n\n3) **Enhanced Generalization**: The balanced dataset produced by SMOTE can help models generalize better to unseen data, as they are exposed to a more diverse range of samples from the minority class.\n\n### ***There is also very important note***:\n\nUsing grid search may greatly differ depending on as chosen parameters as data (for instance, on train_test_split parameter)\n\nDuring finetuning experiments for such parameters, author of this notebook **always tried to get the best for both data with text embeddings and without one.** As a result, models trained on data with text embeddings **always** shows better score on **f1 metric** if the best parameters for each models are chosen precisely\n","metadata":{"id":"ocI3XjeCanrS"}},{"cell_type":"markdown","source":"# Main conclusions\n\nIn this notebook the following steps were made:\n\n1) **Retrieved text embeddings** using reviews from metacritic and rotten tomattoes. These embeddings supplied dataset for oscar prediction. Also there was a bit of cleaning process for dataset to drop some columns and films with the same name (\"West Side Story\")\n\n2) On this dataset **three models are trained**: SVM, logistic regression and random forest.\n\n3) However, initially dataset is imbalanced, so **SMOTE algorithm is applied** to solve this problem\n\n4) Besides, **additional data analysis is present** in the notebook. For this purpose TSNE was used to shrink and plot train data in 2 dimensions. Silhouette score is also applied and according to it and TSNE classes with **SMOTE and text embeddings** are distinguished much better\n\n5) **The same models were trained** on data with SMOTE. According to the results, **models give higher f1 score on data with text embeddings and SMOTE**. The best model trained on data with SMOTE and text embeddings is logistic regression      (*model's parameters could be found in the notebook*) **with train_test_split parameter is 0.2 and f1 is equal to 0.87**","metadata":{"id":"En0sJYnzzMMa"}}]}
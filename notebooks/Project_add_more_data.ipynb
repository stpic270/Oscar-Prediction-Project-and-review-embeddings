{"metadata":{"colab":{"collapsed_sections":["UexmSTZFZ0dt","UddnxSD_QhwN","gxydnexBczaX","uVN9goQoMewd","Xd6XEZEpMmYg","clqQx2byNJ6G","VM_3ex9WeYe-","q-6sdWWiegnN","jo5pjX45Nap7","cG9SbclCN1HQ","QP8qkgehOjb9","18sXoNtY3qoP","4jKttyTZPU7M"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import and download libraries","metadata":{"id":"XKbcD4b5Lucy"}},{"cell_type":"markdown","source":"## Clone git to which text embeddings will be added","metadata":{"id":"UexmSTZFZ0dt"}},{"cell_type":"code","source":"! git clone https://github.com/MateVaradi/OscarPrediction.git # Git from which main data will be retreived","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cOgx4jVi6iJw","outputId":"47a2a62d-043d-488a-a5e7-0b78b0d18ac7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Download selenium on colab","metadata":{"id":"VFk7NYw2ZnP0"}},{"cell_type":"markdown","source":"### ALWAYS CHECK LOGS CAUSE SOMETIMES DIFFERENT LIBRARIES  ARE NEEDED FOR SUCCESSFUL INSTALLATION","metadata":{"id":"Gh-3OEVb0lDD"}},{"cell_type":"code","source":"%%shell\nsudo apt -y update\nsudo apt install libvulkan1\nsudo apt install -y wget curl unzip\nwget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\ndpkg -i libu2f-udev_1.1.4-1_all.deb\nwget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\ndpkg -i google-chrome-stable_current_amd64.deb\nCHROME_DRIVER_VERSION=`curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE`\nwget -N https://chromedriver.storage.googleapis.com/$CHROME_DRIVER_VERSION/chromedriver_linux64.zip -P /tmp/\nunzip -o /tmp/chromedriver_linux64.zip -d /tmp/\nchmod +x /tmp/chromedriver\nmv /tmp/chromedriver /usr/local/bin/chromedriver\npip install selenium\npip install selenium chromedriver_autoinstaller","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EnUs7AVMzyWk","outputId":"cdc5b70b-c36d-4bb4-f016-de00a261bec4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Download some extra packages for parsing and dwonloading datasets","metadata":{"id":"PdSrs7b7Z9uO"}},{"cell_type":"code","source":"! pip install rotten_tomatoes_scraper bs4 lxml IMDbPY kaggle random_user_agent","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ODkdopi5BSQD","outputId":"165c541c-90a1-4dde-8865-83b14397e356"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Upload your kaggle.json (https://www.kaggle.com/discussions/general/156610) file for downloading datasets","metadata":{"id":"MA4myURYaEDQ"}},{"cell_type":"code","source":"!mkdir ~/.kaggle\n!cp kaggle.json ~/.kaggle/","metadata":{"id":"F0Gt-tGAbIKi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! kaggle datasets download -d miazhx/metacritic-movie-reviews\n! kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n! kaggle datasets download -d garcibo/metacritic-movie-15k-review-582k-dataset\n! kaggle datasets download -d mechamod/metacritic-500k-reviews\n! kaggle datasets download -d talha002/rottentomatoes-400k-review\n! kaggle datasets download -d andrezaza/clapper-massive-rotten-tomatoes-movies-and-reviews\n! kaggle datasets download -d unanimad/the-oscar-award\n\n! unzip /content/metacritic-movie-15k-review-582k-dataset.zip -d /content/kaggle_1\n! unzip /content/metacritic-movie-reviews.zip -d /content/kaggle_2\n! unzip /content/imdb-dataset-of-50k-movie-reviews.zip -d /content/kaggle_3\n! unzip /content/metacritic-500k-reviews.zip -d /content/kaggle_4\n! unzip /content/rottentomatoes-400k-review.zip -d /content/kaggle_5\n! unzip /content/clapper-massive-rotten-tomatoes-movies-and-reviews.zip -d /content/kaggle_6\n! unzip /content/the-oscar-award.zip -d /content/kaggle_7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gSEonEM7bQkW","outputId":"1f05a5be-8560-4aac-8041-d76c9690746a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To connect to google drive\nfrom google.colab import drive\n# For data processing\nimport pandas as pd\nimport numpy as np\n# For parsing data\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom rotten_tomatoes_scraper.rt_scraper import MovieScraper\nfrom imdb import Cinemagoer\nimport bs4, lxml\nfrom selenium.webdriver.common.by import By\nfrom selenium import webdriver\nimport chromedriver_autoinstaller\nfrom bs4 import BeautifulSoup\nimport requests\nfrom random_user_agent.user_agent import  UserAgent\nfrom random_user_agent.params import SoftwareName, OperatingSystem\n# For multithreaing processes\nfrom concurrent.futures import ThreadPoolExecutor\nfrom multiprocessing.pool import ThreadPool\n# Insert path to chrome-driver in system\nimport sys\nsys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\nchromedriver_autoinstaller.install()\n# For loading screenshot\nfrom PIL import Image\n# For downloading files\nimport pickle\n# To check processes in python\nfrom tqdm import tqdm\n# To check time and work with dirs\nimport time, os\nfrom multiprocessing import Pool","metadata":{"id":"jZXxC0AyZmPf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7I5jnPu_Z90E","outputId":"276ad770-2917-45cd-dd36-b0b40b580630"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare some dataframes that will be used later","metadata":{"id":"UddnxSD_QhwN"}},{"cell_type":"markdown","source":"## Prepare driver","metadata":{"id":"fJ04Fp5KMJf8"}},{"cell_type":"code","source":"! pip show selenium","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I9_x3iFSQqsP","outputId":"bc87d462-995c-40c1-bf3a-82b92ab0e3c3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_driver():\n\n    \"\"\"\n    This function just prepares drive with some settings\n    \"\"\"\n\n    # Get random user_agent\n    user_agents = [\n               'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.6167.139 Safari/537.36 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)',\n               'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.6167.85 Safari/537.36 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)',\n               'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.6167.85 Safari/537.36 (compatible; Googlebot/2.1; http://www.google.com/bot.html)',\n               'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko; compatible; Googlebot/2.1; +http://www.google.com/bot.html) Chrome/111.0.5563.64 Safari/537.36',\n               'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.6261.94 Safari/537.36 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)',\n               'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.5615.142 Safari/537.36 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)'\n                  ]\n    # Choise randomly user agent\n    user_agent = random.choice(user_agents)\n    print(user_agent)\n\n    # setup chrome options\n    chrome_options = webdriver.ChromeOptions()\n    #run in headless mode\n    chrome_options.add_argument('--headless')\n    # disable sandbox mode\n    chrome_options.add_argument('--no-sandbox')\n    # disable extensions\n    chrome_options.add_argument(\"--disable-extensions\")\n    # Define user\n    chrome_options.add_argument(f\"user-agent={user_agent}\")\n    # disable shared memory usage\n    chrome_options.add_argument('--disable-dev-shm-usage')\n    # disable the AutomationControlled feature of Blink rendering engine\n    chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n    chrome_options.add_experimental_option('useAutomationExtension', False)\n    chrome_options.add_experimental_option(\"prefs\", {\"profile.managed_default_content_settings.images\": 2,})\n    # Disable gpu\n    chrome_options.add_argument(\"--disable-gpu\")\n\n    # set up the webdriver\n    driver = webdriver.Chrome(options=chrome_options)\n\n    return driver","metadata":{"id":"wzEdgCoSR-Vg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"driver = get_driver()","metadata":{"id":"3gs8vAMPXiJP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get screenshot","metadata":{"id":"gxydnexBczaX"}},{"cell_type":"code","source":"driver.get('https://www.rottentomatoes.com/m/happy_gilmore')\npath = '/content/screenshot.jpg'\ndriver.save_screenshot(path)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f-lDJVJdScwh","outputId":"c2b3724c-50b7-4efa-addd-af859479250c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"screenshot = Image.open(path)\nscreenshot","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kEo2zoVJ2smp","outputId":"218401ca-03eb-42d6-8d30-8fa395397b76"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare dataframes","metadata":{"id":"uVN9goQoMewd"}},{"cell_type":"code","source":"# main datasets that are used here for movie analysis\nmetacritic_250k_df = pd.read_csv('/content/kaggle_2/metacritic_reviews.csv', index_col=0)\nhuge_rotten_tomattoes_df = pd.read_csv('/content/kaggle_6/rotten_tomatoes_movie_reviews.csv')\nhuge_tomattoes_movies_df = pd.read_csv('/content/kaggle_6/rotten_tomatoes_movies.csv')\noscar_award_df = pd.read_csv('/content/kaggle_7/the_oscar_award.csv')\n\n# You can uncomment the following datasets and check it\n\n# cleaned_df = pd.read_csv('/content/drive/MyDrive/project/final_simple_project_data.csv', index_col=0)\n# movies_df = pd.read_csv('/content/kaggle_2/metacritic_movies.csv', index_col=0)\n# reviews_50k_df = pd.read_csv('/content/kaggle_3/IMDB Dataset.csv', index_col=0)\n# metacritic_15k_df = pd.read_csv('/content/kaggle_1/reviewDatasetClean.csv', index_col=0, lineterminator='\\n')\n# movies_15k_df = pd.read_csv('/content/kaggle_1/movieDatasetClean.csv', index_col=0)\n# metacritic_500k_df = pd.read_csv('/content/kaggle_4/Metacritic_reviews.csv', index_col=0, sep='µ')\n# rotten_tommatoes_400k_df = pd.read_csv('/content/kaggle_5/rottentomatoes-400k.csv', index_col=0)","metadata":{"id":"k_h3TjDrZxiH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## clone repo for retreiving rotten tomattoes reviews","metadata":{"id":"Xd6XEZEpMmYg"}},{"cell_type":"code","source":"! git clone https://github.com/preritdas/rottentomatoes-python.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vJuz4B4uI4QQ","outputId":"d1301cc7-cce3-4fba-b09a-8a6d7562a50a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /content/rottentomatoes-python","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SkyJAUWJI_vv","outputId":"95a7e43e-b3d6-447d-97e1-447aa1321b47"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import rottentomatoes as rt","metadata":{"id":"16pWhQQ0JDiK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movie = rt.Movie(\"happy gilmore\")","metadata":{"id":"rgmeXobiJJg6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movie.url","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IRNl1PSuJ1gj","outputId":"1b20cd58-9bc3-4b64-a49c-4dbf92e8881b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check oscar winners df","metadata":{"id":"clqQx2byNJ6G"}},{"cell_type":"code","source":"oscar_award_df.info()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_v6P3szSxzs4","outputId":"30ccb199-8ad0-4846-f77a-c105bc3c9577"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oscar_award_df.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IfRHww2Zx37T","outputId":"3c56847c-b095-41d3-9bd0-7011f1413a63"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check oscar-winner categories","metadata":{"id":"VM_3ex9WeYe-"}},{"cell_type":"code","source":"unique_values_oscar_category = oscar_award_df['category'].unique()","metadata":{"id":"XplzZRw_wD-E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_values_oscar_category","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DWBdO35hxu2u","outputId":"1d963d58-608e-4f3f-968e-d93ab9cde0b2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get oscar-winner movies","metadata":{"id":"q-6sdWWiegnN"}},{"cell_type":"code","source":"oscar_winners_df = oscar_award_df[oscar_award_df['winner'].isin([True])]","metadata":{"id":"GCiwoJvnyar9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oscar_winners_df","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LcE1JdgGzJxI","outputId":"b69b5981-5e93-4594-8e96-be6e996cbaec"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop rows with Nan\noscar_winners_df.dropna(inplace=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xBn0huYazbyc","outputId":"4d9c79bf-4ef0-4f46-e3a1-c853309586ad"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oscar_winners_df.info()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"exJ7DBHc3RTH","outputId":"92ab6c91-86b2-4e87-9553-b622d2529ac1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get rotten tomattoes topcritic df and analyze data","metadata":{"id":"jo5pjX45Nap7"}},{"cell_type":"code","source":"huge_rotten_tomattoes_topcritic_df = huge_rotten_tomattoes_df[huge_rotten_tomattoes_df['isTopCritic'].isin([True])]","metadata":{"id":"ktXkB4OZ-xE6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rotten_tommatoes_topcritic_df = pd.merge(huge_rotten_tomattoes_topcritic_df, huge_tomattoes_movies_df[['id', 'title']], on='id')\nrotten_tommatoes_topcritic_df.info()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nnneIkZ3_DRx","outputId":"050af3d8-0947-4005-daab-e6fa6605d325"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compare the number of rotten tomattoes and metacritic reviews for oscar winner movies\n\n### The next cell calculates oscar-winner movies at any nominations and checks how many films from it have metacritic and rotten tomattoes reviews","metadata":{"id":"cG9SbclCN1HQ"}},{"cell_type":"code","source":"main_category_winners_unique_names = list(set(oscar_winners_df['film'].tolist()))\nprint('Len of oscar winners list - ', len(main_category_winners_unique_names))\nmain_category_winners_metacritic_df = metacritic_250k_df[metacritic_250k_df['movie_title'].isin(main_category_winners_unique_names)]\nmain_category_winners_metacritic_unique_movie = list(set(main_category_winners_metacritic_df['movie_title'].tolist()))\nprint(\"Len of oscar winners list with METACRITIC reviews - \", len(main_category_winners_metacritic_unique_movie))\n\nmain_category_winners_tomattoes_df = rotten_tommatoes_topcritic_df[rotten_tommatoes_topcritic_df['title'].isin(main_category_winners_unique_names)]\nmain_category_winners_tomattoes_unique_movie = list(set(main_category_winners_tomattoes_df['title'].tolist()))\nprint(\"Len of oscar winners list with ROTTEN TOMATTOES reviews - \", len(main_category_winners_tomattoes_unique_movie))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7vy7zp3e3xhD","outputId":"fbb84b8b-42ef-46d8-ff44-7d31beb81d87"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **As you can see there are many movies without reviews. Besides, main dataset with nominations lack data**\n\n### *Cause of these reasons the different dataset (it contains much more data) is used in similar way - rotten tomattoes and metacritic reviews are added to it from previous datasets. Films that  still lack reviews will be supplied text data using parsing*","metadata":{"id":"mEpRrSREfzo9"}},{"cell_type":"markdown","source":"# Prepare MAIN dataframe with different sets of movies that include additional data. Besides to that data, reviews will be added to this df","metadata":{"id":"QP8qkgehOjb9"}},{"cell_type":"code","source":"variable_selection = pd.read_excel('/content/OscarPrediction/predictor_selection.xlsx')\nvariable_selection.info()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WzjYqwXO6eoP","outputId":"29e917bd-24a5-4a3c-f181-1ad844dd832a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check how many movies lack metacritic and rotten tomattoes reviews in main dataframe as we did before","metadata":{"id":"67pb81VwO5EC"}},{"cell_type":"code","source":"df_picture = pd.read_csv('/content/OscarPrediction/data/oscardata_bestpicture.csv')\n\nmain_category_winners_unique_names = list(set(df_picture['Film'].tolist()))\nprint('Len of oscar winners list - ', len(main_category_winners_unique_names))\nmain_category_winners_metacritic_df = metacritic_250k_df[metacritic_250k_df['movie_title'].isin(main_category_winners_unique_names)]\nmain_category_winners_metacritic_unique_movie = list(set(main_category_winners_metacritic_df['movie_title'].tolist()))\nprint(\"Len oscar winners list with METACRITIC reviews - \", len(main_category_winners_metacritic_unique_movie))\n\nmain_category_winners_tomattoes_df = rotten_tommatoes_topcritic_df[rotten_tommatoes_topcritic_df['title'].isin(main_category_winners_unique_names)]\nmain_category_winners_tomattoes_unique_movie = list(set(main_category_winners_tomattoes_df['title'].tolist()))\nprint(\"Len oscar winners list with ROTTEN TOMATTOES reviews - \", len(main_category_winners_tomattoes_unique_movie))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gibqpGk9ZTj","outputId":"a8a7a31c-cd02-4040-a856-5a48c42dc9c8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Form unique sets for later use","metadata":{"id":"-INm9WleR6z7"}},{"cell_type":"code","source":"unique_set = set(main_category_winners_unique_names)\nmetacritic_set = set(main_category_winners_metacritic_unique_movie)\ntomattoes_set = set(main_category_winners_tomattoes_unique_movie)\nmovies_without_metacritic_reviews = list(unique_set.difference(metacritic_set))\nmovies_without_rt_reviews = list(unique_set.difference(tomattoes_set))\nprint(movies_without_metacritic_reviews)\nprint(movies_without_rt_reviews)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kW-4uuKIDQYE","outputId":"a0efc2f3-7023-4acc-9ce0-ed70801b4c8d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***PARSING!!!***\n\n#You can skip the following cells and just download missing reviews or check how the data was got","metadata":{"id":"Dr76lfRpSC57"}},{"cell_type":"markdown","source":"### Brief information about multithreading and multiprocesses\n\nhttps://www.geeksforgeeks.org/multithreading-or-multiprocessing-with-python-and-selenium/\n\n***Multithreading and multiprocessing*** are two popular approaches for improving the performance of a program by allowing it to run tasks in parallel. These approaches can be particularly useful when working with Python and Selenium, as they allow you to perform multiple actions simultaneously, such as automating the testing of a web application.\n\nIt is important to understand the **fundamental differences** between these approaches.\n\n***Multithreading:*** Multithreading is the ability of a central processing unit (CPU) (or a single core in a multi-core processor) to provide multiple threads of execution concurrently, supported by the operating system. This allows a program to run multiple threads concurrently, with each thread running a separate task. In Python, the threading module provides support for multithreading.\n\n***Multiprocessing:*** Multiprocessing is the ability to execute multiple concurrent processes within a system. Unlike multithreading, which allows multiple threads to run on a single CPU, multiprocessing allows a program to run multiple processes concurrently, each on a separate CPU or core. In Python, the multiprocessing module provides support for multiprocessing.\nIt is important to note that multithreading and multiprocessing are not mutually exclusive, and it is possible to use both approaches in a single program. However, there are some key differences to consider when deciding which approach is best for a given task.\n\n***Performance:*** In general, multiprocessing is more efficient than multithreading, as it allows a program to take full advantage of multiple CPU cores. However, multithreading can still be useful in certain situations, such as when a program is **I/O bound** (i.e., waiting for input/output operations to complete) rather than CPU bound.\n\n**Shared state:** One of the major differences between multithreading and multiprocessing is the way that they handle shared state. In multithreading, threads share the same memory space, which means that they can access and modify shared variables. In contrast, processes in multiprocessing do not share a memory and must communicate with each other through interprocess communication (IPC) mechanisms such as pipes or shared memory.\n\n**Concurrency:** Both multithreading and multiprocessing allow a program to execute tasks concurrently. However, there are some key differences to consider when it comes to concurrency. In multithreading, the Python interpreter is responsible for managing the threads, meaning that the program can only run as many threads as CPU cores. In contrast, multiprocessing allows a program to create as many processes as there are CPU cores, which can potentially lead to better performance.\n\n\n### ***Cause of this reasons multithreading will be used to get urls for websites and multiprocessing for scraping reviews from rotten tomattoes and metacritic. Process of cpu will be always 2 for colab because it has 2 cpu and further increasing will not have much of improving. For multithreading you can define your own number/ In this notebook usually used 4-8***","metadata":{"id":"18sXoNtY3qoP"}},{"cell_type":"code","source":"from psutil import cpu_count\n# This code will return the number of CPU\nprint(\"Number of CPU: \", cpu_count())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"16qjkmG27Uqw","outputId":"fe06c5d1-cae3-4a30-e4c2-3f98fe14b1d5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_rt_urls(movie_names):\n\n    \"\"\"\n    This function adds url to films that are without rt reviews using\n    external dict urls_wt_rt_dict\n\n    Parameters:\n    movie_names (list): list that contains movie names\n\n    Returns:\n    dict: dict with urls\n    \"\"\"\n\n    for movie_name in tqdm(movie_names, total=len(movie_names)):\n        movie = rt.Movie(movie_name)\n        urls_wt_rt_dict[movie_name] = movie.url\n\n    return urls_wt_rt_dict\n\ndef use_threadpool(cpu, function, data):\n\n    \"\"\"\n    This is the main function that is used for MULTITHREADING in the entire\n    notebook\n\n    Parameters:\n    cpu (int): Threads number\n    function (object): function which is used for multithreading\n    **data_dict (dict): Dict that always has 2 values: data which are used in\n    function and drivers - list with drivers (it equals None if drivers are not\n    used in function)\n    \"\"\"\n\n    with ThreadPoolExecutor(cpu) as p:\n\n                  p.map(\n                        function,\n                        data\n                        )\n\ndef use_mp_pool(cpu, function, data):\n\n    \"\"\"\n    This is the main function that is used for MULTIPROCESSING in the entire\n    notebook\n\n    Parameters:\n    cpu (int): CPU number\n    function (object): function which is used for multiprocessing\n    data (list): data splitted for the all processes\n\n    Return:\n    bucket (list): list with content from the multpipocessing\n    t (float): time for this function (seconds)\n    \"\"\"\n\n    start_time = time.time()\n\n    # with ThreadPoolExecutor(cpu) as p:\n    with Pool(cpu) as p:\n\n        bucket = p.map(\n                      function,\n                      data\n                      )\n\n    end_time = time.time()\n    t = end_time-start_time\n\n    return bucket, t\n\ndef parse_multiple_times(cpu, function, attempt_number, data, wait_time=5):\n\n    \"\"\"\n    This is the function that is used for trying the MULTIPROCESSING\n    attempt_number tumes\n\n    Parameters:\n    cpu (int): CPU number\n    function (object): function which is used for multiprocessing\n    attemot_number (int): number to try multiprocessing function\n    data (list): data splitted for the all processes\n\n    Return:\n    bucket (list): list with content from the multpipocessing\n    t (float): time for this function (seconds)\n    \"\"\"\n\n    start_time = time.time()\n    old_bucket = []\n\n    for a in range(attempt_number):\n\n        print(\"-\"*100)\n        print(f\"ATTEMPT NO {a+1}\")\n\n        bucket, _ = use_mp_pool(cpu, function, [(d, wait_time) for d in data])\n\n        data_wt_reviews = [k for mc_dict in bucket for k,v in mc_dict.items() if not v]\n\n        if not data_wt_reviews:\n\n            end_time = time.time()\n            t = end_time-start_time\n            return bucket, t\n\n        else:\n\n            print(f\"\\nNUMBER URLS THAT WEBDRIVER DIDN'T CONNECT TO = {len(data_wt_reviews)}\")\n            print(f\"\\nTHEIR NAMES = {data_wt_reviews}\")\n            data = [d for chunk in data for d in chunk if d in data_wt_reviews]\n            data = np.array_split(data, cpu)\n            old_bucket.extend(bucket)\n            if a + 1 == attempt_number:\n                break\n            print(\"SLEEP FOR 15 SECONDS BEFORE THE NEXT TRY\")\n            time.sleep(15)\n\n            continue\n\n    end_time = time.time()\n    t = end_time-start_time\n\n    return old_bucket, t","metadata":{"id":"dOpnUAygOoLv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get rt urls before parsing reviews","metadata":{"id":"4jKttyTZPU7M"}},{"cell_type":"code","source":"# Define threads number and data chunks\ncpu=4\nsp_array_movie_names = np.array_split(movies_without_rt_reviews,cpu)","metadata":{"id":"aWxrS4EmUD85"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get urls for rotten tomattoes\nurls_wt_rt_dict = {name:None for name in movies_without_rt_reviews}\n\nuse_threadpool(cpu, create_rt_urls,\n               data=sp_array_movie_names)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EixV1z5W7h43","outputId":"55b4a0cb-6e84-4852-aa72-306bd1a01996"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get dict with rotten tomattoes missing reviews","metadata":{"id":"sf5FdaosPlgI"}},{"cell_type":"code","source":"def get_rt_reviews(params_tuple):\n\n    \"\"\"\n    This is the function that works in a similar way to calculate_current_list -\n    just fill in reviews that parse using driver\n\n    Parameters:\n    movie_names (list): list with movie names. Using them as a key to tomattoes\n    urls\n    driver: Selenium driver to get data\n    \"\"\"\n    movie_names, time_to_sleep = params_tuple\n    current_i = 1\n    rt_dict = {name:[] for name in movie_names}\n    driver= get_driver()\n    i = -1\n\n    for movie_name in tqdm(movie_names, total=len(movie_names), unit='movie_name'):\n        print(f'\\n{movie_name}')\n        i += 1\n        # Get url\n        url = urls_wt_rt_dict[movie_name]\n        # Get connection to the driver\n        try:\n            # Get url\n            url += '/reviews?type=top_critics'\n            driver.get(url)\n            time.sleep(time_to_sleep)\n            current_i=1\n\n        except Exception as e:\n            print(f\"\\nTIMEOUT EXCEPTION OCCURED IN {current_i} TIME IN A ROW\")\n            current_i += 1\n\n            if current_i > 5:\n                print(f\"DRIVER STOPPED CONNECTING TO THE URLS, UPDATE THE ALL ITERATION\")\n                break\n\n            driver = get_driver()\n\n            continue\n\n        # Upload all reviews via LOAD MORE button on the rt site\n        movie_reviews = driver.find_elements(By.CSS_SELECTOR, 'p.review-text')\n        old_review_number = 10000000\n        new_review_number = len(movie_reviews)\n        # Check if amount of reviews are changed\n        while new_review_number != old_review_number:\n            old_review_number = new_review_number\n            button = driver.find_elements(By.CSS_SELECTOR, 'div.load-more-container')\n            button[0].click()\n            time.sleep(2)\n            movie_reviews = driver.find_elements(By.CSS_SELECTOR, 'p.review-text')\n            new_review_number = len(movie_reviews)\n\n        # Get reviews\n        for movie_review in movie_reviews:\n            if len(movie_review.text) == 0:\n                continue\n            # Add reviews to the dict\n            rt_dict[movie_name].append(movie_review.text)\n\n        if i%10 == 0:\n            driver.quit()\n            driver = get_driver()\n\n    driver.quit()\n\n    return rt_dict","metadata":{"id":"Sl4EPBvPQZ5B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define parameters for multithreading\ncpu=2\nsp_array_movie_names = np.array_split(movies_without_rt_reviews,cpu)","metadata":{"id":"w3RDgMhUbm3W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using wait_time = 0 for rotten tomattoes reviews is ok even with vpn but you could define your time","metadata":{"id":"Raoa4Zo4dIfm"}},{"cell_type":"code","source":"bucket, t = parse_multiple_times(cpu, get_rt_reviews, attempt_number=2,\n                                 data=sp_array_movie_names, wait_time=0)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qQan1672lR8i","outputId":"033bb194-64c7-4fd5-8d12-1ee580c2f2d0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the dict with rt reviews\nrt_dict = {k:v for d in bucket for k, v in d.items()}","metadata":{"id":"ghR8N8afEZhq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(rt_dict)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DugAEdnKaJmV","outputId":"6160d565-f922-4741-8b49-32b59d079634"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get missing metacritic reviews using similar way.\n## ***TURN ON VPN IF THERE ARE SOME CONSTRICTIONS WITH YOUR NET***","metadata":{"id":"Rc-X8RcJPuxi"}},{"cell_type":"markdown","source":"### Get review for interstellar for instance","metadata":{"id":"z_f-izBNpYDh"}},{"cell_type":"code","source":"driver = get_driver()\nurl = 'https://www.metacritic.com/movie/interstellar/critic-reviews/'\ndriver.get(url)","metadata":{"id":"v0p8g2RffrvN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movie_reviews = driver.find_elements(By.CSS_SELECTOR, 'div.c-siteReview_quote')\nmovie_reviews[3].text","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"A9btZ57ZrlTW","outputId":"333a0812-676e-46de-8443-d430e1997b1f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"driver.quit()","metadata":{"id":"YR6P0nKGvvZS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's collect *metacritic* names\n*Metacritic* names - these are just names that used in url to film in metacritic url. However, there are some difficult cases when multiple movies have the same name or there is tv show and movie with the same name. Cause of such problem metacritic names are retrieved from the link on metacritic web","metadata":{"id":"icEQykfz-ZP6"}},{"cell_type":"code","source":"def get_movies_wt_mc(movie_names, driver=None):\n\n    \"\"\"\n    This function uses film names and seacrh on metacritic search web. If movie\n    with the name exists it appends it to list with reviews and vice versa\n\n    Parameters:\n    movie_names (list): list with movie titles without metacritic reviews\n    \"\"\"\n\n    for movie_title in tqdm(movie_names, total=len(movie_names)): # iterate over movie titles\n\n        # Retrieve the first word from the title\n        first_title_word = movie_title.split()[0].lower()\n        # Replace spaces with metacritic pattern (%20 in our case)\n        modified_movie_title = movie_title.lower().replace(' ', '%20')\n        # Get search url for all variants of movies, tv shows with common name\n        search_url = f'https://www.metacritic.com/search/{modified_movie_title}/?page=1&category=2'\n        # Make soup from the search url\n        response = requests.get(search_url, headers = user_agent)\n        soup = BeautifulSoup(response.content, 'html.parser')\n        # Get containers (tv shows, movies) with information\n        containers = soup.find_all('div', class_='g-grid-container u-grid-columns')\n        # Iterate over tv shows and movies\n        for i, container in enumerate(containers[0:4]):\n            metacritic_name = container.find('a').get('href')\n\n            # If name is the same and container has movie pattern then append it\n            if 'movie' in metacritic_name and first_title_word in metacritic_name:\n                metacritic_names.append((metacritic_name, movie_title))\n                break\n\n            # If there is not movie with such names then movie does not have metacritic reviews\n            if i == 3:\n                empty_metacritic_reviews.append(movie_title)","metadata":{"id":"Lie7jpeDBM_o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define parameters for multithreading and lists for function\ncpu=8\nsp_array_movie_names = np.array_split(movies_without_metacritic_reviews,cpu)\n\nuser_agent = {'User-agent': 'Mozilla/5.0'}\nmetacritic_names = []\nempty_metacritic_reviews = []","metadata":{"id":"nd8L3tSRl0O1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply multithreading\nuse_threadpool(cpu, get_movies_wt_mc,\n               data=sp_array_movie_names)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t7Fks_QimARt","outputId":"262c3ba2-9c3f-4228-8248-0d63e52a2194"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check movies without reviews\n","metadata":{"id":"keLf-SulEurP"}},{"cell_type":"code","source":"movies_without_mc_reviews = [i for _, i in metacritic_names]\nmovies_without_mc_dict = {name:pair for name, pair in zip(movies_without_mc_reviews, metacritic_names)}\nprint(\"Number of movies with reviews - \", len(movies_without_mc_reviews))\nprint(\"Number of movies without reviews - \", len(empty_metacritic_reviews))\nempty_metacritic_reviews","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PccSgnZ6Dp4s","outputId":"149c2e3c-decf-47d2-e815-bf283a13ab9a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get urls for metacritic reviews","metadata":{"id":"IHtQ8RddrgXx"}},{"cell_type":"code","source":"def create_mc_urls(movie_names, driver=None):\n\n    \"\"\"\n    This function works in the same way as create_rt_urls that was defined\n    previously\n\n    Parameters:\n    movie_names (list): list that contains movie names\n\n    Returns:\n    dict: dict with urls\n    \"\"\"\n\n    for movie_title in tqdm(movie_names, total=len(movie_names)):\n        metacritic_name, _ = movies_without_mc_dict[movie_title]\n        url = f'https://www.metacritic.com{metacritic_name}critic-reviews/'\n        urls_wt_mc_dict[movie_title] = url\n\n    return urls_wt_mc_dict","metadata":{"id":"bYfZ8iertDum"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define parameters for multithreading\ncpu=4\nsp_array_movie_names = np.array_split(movies_without_mc_reviews,cpu)","metadata":{"id":"K-RHeznLsqtC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urls_wt_mc_dict = {name:None for name in movies_without_mc_reviews}\nuse_threadpool(cpu, create_mc_urls,\n               data=sp_array_movie_names)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DtJMhwnLskqu","outputId":"588f1e01-aecd-437f-a6a0-6263011b57df"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_mc_reviews(params_tuple):\n\n    \"\"\"\n    This is the function that works in a similar way to get_mc_reviews -\n    just fill in reviews that parse using driver\n\n    Parameters:\n    movie_names (list): list with movie names. Using them as a key to metacritic\n    urls\n\n    driver: Selenium driver to get data\n    \"\"\"\n\n    movie_names, time_wait = params_tuple\n    driver = get_driver()\n    mc_dict = {name:[] for name in movie_names}\n    current_i=1\n    i = -1\n    # Iterate over movie_names\n    for movie_name in tqdm(movie_names, total=len(movie_names)):\n        i += 1\n        print(\" Name of movie - \", movie_name)\n\n        # Get metacritic url\n        try:\n            url = urls_wt_mc_dict[movie_name]\n            driver.get(url)\n            WebDriverWait(driver, time_wait).until(EC.presence_of_element_located((By.XPATH, '//div[@class=\"c-siteLogo c-siteFooter_logo\"]')))\n            current_i=1\n\n        except Exception as e:\n            print(f\"TIMEOUT EXCEPTION OCCURED IN {current_i} TIME IN A ROW\")\n            current_i += 1\n\n            if current_i > 5:\n                print(f\"DRIVER STOPPED CONNECTING TO THE URLS, UPDATE THE ALL ITERATION\")\n                break\n\n            driver.quit()\n            driver = get_driver()\n\n            continue\n\n        # Get reviews\n        movie_reviews = driver.find_elements(By.CSS_SELECTOR, 'div.c-siteReview_quote')\n        # Append review to a list\n        for movie_review in movie_reviews:\n            mc_dict[movie_name].append(movie_review.text)\n\n        if i%10==0:\n            print(\"UPDATE DRIVER\")\n            driver.quit(); driver=get_driver()\n\n    driver.quit()\n\n    return mc_dict","metadata":{"id":"Dk476N5nK_FI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Metacritic is a bit difficult site to retrieve site at least for the author of this notebook. Sometimes you can get connection to some url and get reviews and sometimes you cannot. Several techniques are already in use to avoid this like always changing driver with new good user from defined user agents. Besides ,notebook utilizes WebDriverWait\n\n### Also the speed of parsing strongly depends on your net and your user agent. In this notebook user agents has verty good speed. So don't worry if you run it in google colab. However, there may be some problem if you use different net like Opera or Firefox\n\n### ***CHECK THE OTHER USER-AGENTS*** - ***https://explore.whatismybrowser.com/useragents/explore/software_name/googlebot/1***","metadata":{"id":"uE0LVW5l-V7c"}},{"cell_type":"code","source":"import random","metadata":{"id":"ygglcuxphr4l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define parameters for multithreading\ncpu=2\nsp_array_movie_names = np.array_split(movies_without_mc_reviews,cpu)","metadata":{"id":"iXr_Jq3eWeVK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bucket, t = parse_multiple_times(cpu, get_mc_reviews, attempt_number=2,\n                                 data=sp_array_movie_names, wait_time=10)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"panZevuByIwm","outputId":"81837571-d2b1-48db-d04b-8b2d95f7ceaf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/content/drive/MyDrive/project/full_rt_20_mc_reviews_dicts/full_mc_dict.pkl', 'rb') as file:\n    full_mc_dict = pickle.load(file)\n    full_mc_dict = {key:full_mc_dict[key] for key in movies_without_mc_reviews}","metadata":{"id":"dXfzw3V90oqD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_with_reviews = [v for mc_dict in bucket for k,v in mc_dict.items() if v]\nprint(len(data_with_reviews))\nprint(\"TIME=\", t)\nprint(\"REVIEWS NUMBER\", len([review for reviews in data_with_reviews for review in reviews]))\n\ndata_with_correct_reviews = [v for k,v in full_mc_dict.items() if v]\nprint(len(data_with_correct_reviews))\nprint(\"CORRECT REVIEWS NUMBER\", len([review for reviews in data_with_correct_reviews for review in reviews]))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JXlZI2wjP-Py","outputId":"ba5feab4-b404-4ab8-9051-0f81628b359b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save dicts with reviews","metadata":{"id":"H7P9uEyfS7ar"}},{"cell_type":"code","source":"mc_dict = {k:v for d in bucket for k,v in d.items()}","metadata":{"id":"0FI1yqLeSZ2X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/content/drive/MyDrive/project/rt_mc_text_reviews/rt_dict.pkl', 'wb') as file:\n    pickle.dump(rt_dict, file)\n\nwith open('/content/drive/MyDrive/project/rt_mc_text_reviews/mc_dict.pkl', 'wb') as file:\n    pickle.dump(mc_dict, file)","metadata":{"id":"-uX3eWd7SSYi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Upload reviews","metadata":{"id":"_ZKG-RJwSR9P"}},{"cell_type":"code","source":"with open('/content/drive/MyDrive/project/rt_mc_text_reviews/rt_dict.pkl', 'rb') as file:\n    rt_dict = pickle.load(file)\n\nwith open('/content/drive/MyDrive/project/rt_mc_text_reviews/mc_dict.pkl', 'rb') as file:\n    mc_dict = pickle.load(file)","metadata":{"id":"rEkklQaYSVcS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_category_winners_unique_names = list(set(df_picture['Film'].tolist()))\nprint('Len of oscar winners list - ', len(main_category_winners_unique_names))\nmain_category_winners_metacritic_df = metacritic_250k_df[metacritic_250k_df['movie_title'].isin(main_category_winners_unique_names)]\nmain_category_winners_metacritic_unique_movie = list(set(main_category_winners_metacritic_df['movie_title'].tolist()))\nprint(\"Len oscar winners list with METACRITIC reviews - \", len(main_category_winners_metacritic_unique_movie))\n\nmain_category_winners_tomattoes_df = rotten_tommatoes_topcritic_df[rotten_tommatoes_topcritic_df['title'].isin(main_category_winners_unique_names)]\nmain_category_winners_tomattoes_unique_movie = list(set(main_category_winners_tomattoes_df['title'].tolist()))\nprint(\"Len oscar winners list with ROTTEN TOMATTOES reviews - \", len(main_category_winners_tomattoes_unique_movie))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BvuvRuuLTLI-","outputId":"f52d0f25-2fa3-4635-aa6a-ab42cbcc1a24"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run the next cells to get movie titles and its text reviews as lists","metadata":{"id":"kWEudOj3TNC8"}},{"cell_type":"code","source":"temporary_df = pd.DataFrame(columns=['title', 'reviewText'])\nfor movie_name, reviews in rt_dict.items():\n    for review in reviews:\n        temporary_df = temporary_df.append({'title':movie_name, 'reviewText':review}, ignore_index=True)\n\n# Concat data\nfull_main_rt_df = pd.concat([temporary_df,\n                            main_category_winners_tomattoes_df])\n\ntemporary_df = pd.DataFrame(columns=['movie_title', 'text'])\nfor movie_name, reviews in mc_dict.items():\n    for review in reviews:\n        temporary_df = temporary_df.append({'movie_title':movie_name, 'text':review}, ignore_index=True)\n\n# Concat data\nfull_main_mc_df = pd.concat([temporary_df,\n                             main_category_winners_metacritic_df])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SiZYNcGQWVpp","outputId":"5f38abc4-3ad0-4e84-a7c6-a4844673c720"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reset index\nfull_main_rt_df = full_main_rt_df.reset_index(drop=True)\nfull_main_mc_df = full_main_mc_df.reset_index(drop=True)","metadata":{"id":"9uIWWfoZDJ8A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rename columns\nfull_main_rt_df.rename(columns={'title':'movie_title', 'reviewText':'text'}, inplace=True)","metadata":{"id":"QK7sf3JFaXq0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_main_winners_columns(df):\n\n    unique_names_list_column, raw_reviews_list_column = [], []\n    # reviews_by_name_list_column = []\n\n    for i, name in enumerate(df['movie_title']):\n\n        if name not in unique_names_list_column:\n\n            if unique_names_list_column:\n                raw_reviews_list_column.append(raw_reviews)\n                # reviews_by_name_list_column.append(reviews_by_name_dict)\n\n            unique_names_list_column.append(name)\n            raw_reviews = []\n            # reviews_by_name_dict = {}\n\n        text_review = df['text'][i]\n        # author_review = df['critic_name'][i]\n\n        if str(text_review)!='nan':\n            raw_reviews.append(text_review)\n\n        # if str(text_review)!='nan' and str(author_review)!='nan':\n            # reviews_by_name_dict[author_review] = text_review\n\n        if i+1 == len(df['text']):\n            raw_reviews_list_column.append(raw_reviews)\n            # reviews_by_name_list_column.append(reviews_by_name_dict)\n\n    return unique_names_list_column, raw_reviews_list_column # , reviews_by_name_list_column","metadata":{"id":"kX66s7J0Tx23"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_rt_names_list_column, raw_rt_reviews_list_column = convert_main_winners_columns(full_main_rt_df)\nunique_mc_names_list_column, raw_mc_reviews_list_column = convert_main_winners_columns(full_main_mc_df)\n\nfull_rt_dict = dict(zip(unique_rt_names_list_column, raw_rt_reviews_list_column))\nfull_mc_dict = dict(zip(unique_mc_names_list_column, raw_mc_reviews_list_column))","metadata":{"id":"9aB78OGICugt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save final  dicts","metadata":{"id":"ylwr9fvjXnx0"}},{"cell_type":"code","source":"# Save dicts\nwith open('/content/drive/MyDrive/project/full_rt_mc_reviews_dicts/full_rt_dict.pkl', 'wb') as file:\n    pickle.dump(full_rt_dict, file)\n\nwith open('/content/drive/MyDrive/project/full_rt_mc_reviews_dicts/full_mc_dict.pkl', 'wb') as file:\n    pickle.dump(full_mc_dict, file)","metadata":{"id":"yxxIjm0FYh6_"},"execution_count":null,"outputs":[]}]}